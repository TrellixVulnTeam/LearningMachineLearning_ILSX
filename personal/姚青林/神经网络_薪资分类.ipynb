{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "神经网络-薪资分类.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4CwNxDlnddI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from numpy.linalg import inv\n",
        "from math import floor, log\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.max_rows = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynfnvHbhnfaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataProcess_X(rawData):\n",
        "  \n",
        "  # 先去除掉 sex，如果有 income 就去除掉， 没有就算了\n",
        "  # 因为 sex 是伯努利分布， 就只将 男女 变成 0，1 就好\n",
        "  if 'income' in rawData.columns:\n",
        "    Data = rawData.drop(['sex', 'income'], axis=1)\n",
        "  else:\n",
        "    Data = rawData.drop(['sex'], axis=1)\n",
        "    \n",
        "  # 将 object 的列先获取出来， ‘object’ 就是字符串的意思。 一般来说这是类别属性， 离散随机变量\n",
        "  listObjectColumn = [col for col in Data.columns if Data[col].dtypes == 'object']\n",
        "  # 将非 object 的列获取出来， 那就是数字类型的。 连续型的随机变量\n",
        "  listNonObjectColumn = [x for x in list(Data) if x not in listObjectColumn]\n",
        "  \n",
        "  # 将数据进行切分， 把连续型的数据和非连续性的数据切分开来\n",
        "  ObjectData = Data[listObjectColumn]\n",
        "  NonObjectData = Data[listNonObjectColumn]\n",
        "  \n",
        "  # 将之前的 sex 列 变成 01 插入\n",
        "  NonObjectData.insert(0, 'sex', (rawData['sex'] == 'Female').astype(np.int))\n",
        "  \n",
        "  # 将离散随机变量独热编码\n",
        "  ObjectData = pd.get_dummies(ObjectData)\n",
        "  \n",
        "  # 再将内容组合到一起\n",
        "  Data = pd.concat([NonObjectData, ObjectData], axis=1)\n",
        "  Data_x = Data.astype('int64')\n",
        "  \n",
        "  # 中心化内容\n",
        "  Data_x = (Data_x - Data_x.mean()) / Data_x.std()\n",
        "  \n",
        "  return Data_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXGZYxo0t7aL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataProcess_Y(rawData):\n",
        "  df_y = rawData['income']\n",
        "  Data_y = pd.DataFrame((df_y == '>50K').astype('int64'), columns=['income'])\n",
        "  return Data_y['income']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9OR2HZPtSE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'], skipinitialspace=True)\n",
        "testData = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'], skipinitialspace=True, skiprows=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d2-z6X3tZOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_feature = dataProcess_X(trainData).drop(['native-country_Holand-Netherlands'], axis=1).values\n",
        "test_feature = dataProcess_X(testData).values\n",
        "train_label = dataProcess_Y(trainData).values\n",
        "test_label = dataProcess_Y(testData).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1vkp6YQoSyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 建立起来神经网络\n",
        "baseline_model = keras.Sequential([\n",
        "    # `input_shape` is only required here so that `.summary` works.\n",
        "    keras.layers.Dense(1000, activation=tf.nn.relu, input_shape=(106,)),\n",
        "    keras.layers.Dense(500, activation=tf.nn.relu),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    #keras.layers.Dense(16, activation=tf.nn.relu),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    #keras.layers.Dense(8, activation=tf.nn.relu),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4feFlOHt-O5",
        "colab_type": "code",
        "outputId": "b8e9790a-224b-414c-e06f-748fa80c0bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# 将神经网络进行参数设置\n",
        "\n",
        "# Adam 是 一种目前公认的最好的自适应学习率的梯度下降法\n",
        "baseline_model.compile(optimizer='adam',\n",
        "                       # 指定了使用交叉熵作为损失函数\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['accuracy', 'binary_crossentropy'])\n",
        "\n",
        "baseline_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 1000)              107000    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 500)               500500    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 501       \n",
            "=================================================================\n",
            "Total params: 608,001\n",
            "Trainable params: 608,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0fl3JJ9uP31",
        "colab_type": "code",
        "outputId": "f35c456e-3fb4-436a-92e4-6318ba96a811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "print(train_feature.shape)\n",
        "print(train_label.shape)\n",
        "# 训练模型\n",
        "# model.fit(train_feature, train_label, epochs=5)\n",
        "# test_loss, test_acc = model.evaluate(test_feature, test_label)\n",
        "# print('Test accuracy:', test_acc)\n",
        "\n",
        "baseline_history = baseline_model.fit(train_feature,\n",
        "                                      train_label,\n",
        "                                      epochs=20,\n",
        "                                      batch_size=512,\n",
        "                                      validation_data=(test_feature, test_label),\n",
        "                                      verbose=2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32561, 106)\n",
            "(32561,)\n",
            "Train on 32561 samples, validate on 16281 samples\n",
            "Epoch 1/20\n",
            "32561/32561 - 3s - loss: 0.3557 - acc: 0.8342 - binary_crossentropy: 0.3557 - val_loss: 0.3857 - val_acc: 0.8377 - val_binary_crossentropy: 0.3857\n",
            "Epoch 2/20\n",
            "32561/32561 - 3s - loss: 0.3135 - acc: 0.8540 - binary_crossentropy: 0.3135 - val_loss: 0.5200 - val_acc: 0.7973 - val_binary_crossentropy: 0.5200\n",
            "Epoch 3/20\n",
            "32561/32561 - 3s - loss: 0.3028 - acc: 0.8578 - binary_crossentropy: 0.3028 - val_loss: 0.5547 - val_acc: 0.7912 - val_binary_crossentropy: 0.5547\n",
            "Epoch 4/20\n",
            "32561/32561 - 3s - loss: 0.2967 - acc: 0.8616 - binary_crossentropy: 0.2967 - val_loss: 0.5741 - val_acc: 0.7975 - val_binary_crossentropy: 0.5741\n",
            "Epoch 5/20\n",
            "32561/32561 - 3s - loss: 0.2925 - acc: 0.8635 - binary_crossentropy: 0.2925 - val_loss: 0.6063 - val_acc: 0.7855 - val_binary_crossentropy: 0.6063\n",
            "Epoch 6/20\n",
            "32561/32561 - 3s - loss: 0.2869 - acc: 0.8656 - binary_crossentropy: 0.2869 - val_loss: 0.6097 - val_acc: 0.7906 - val_binary_crossentropy: 0.6097\n",
            "Epoch 7/20\n",
            "32561/32561 - 3s - loss: 0.2828 - acc: 0.8679 - binary_crossentropy: 0.2828 - val_loss: 0.6340 - val_acc: 0.7859 - val_binary_crossentropy: 0.6340\n",
            "Epoch 8/20\n",
            "32561/32561 - 3s - loss: 0.2770 - acc: 0.8702 - binary_crossentropy: 0.2770 - val_loss: 0.5888 - val_acc: 0.8132 - val_binary_crossentropy: 0.5888\n",
            "Epoch 9/20\n",
            "32561/32561 - 3s - loss: 0.2751 - acc: 0.8722 - binary_crossentropy: 0.2751 - val_loss: 0.5659 - val_acc: 0.8269 - val_binary_crossentropy: 0.5659\n",
            "Epoch 10/20\n",
            "32561/32561 - 3s - loss: 0.2716 - acc: 0.8726 - binary_crossentropy: 0.2716 - val_loss: 0.7058 - val_acc: 0.7937 - val_binary_crossentropy: 0.7058\n",
            "Epoch 11/20\n",
            "32561/32561 - 3s - loss: 0.2659 - acc: 0.8755 - binary_crossentropy: 0.2659 - val_loss: 0.6835 - val_acc: 0.8072 - val_binary_crossentropy: 0.6835\n",
            "Epoch 12/20\n",
            "32561/32561 - 3s - loss: 0.2660 - acc: 0.8761 - binary_crossentropy: 0.2660 - val_loss: 0.7902 - val_acc: 0.7778 - val_binary_crossentropy: 0.7902\n",
            "Epoch 13/20\n",
            "32561/32561 - 3s - loss: 0.2581 - acc: 0.8800 - binary_crossentropy: 0.2581 - val_loss: 0.6739 - val_acc: 0.8215 - val_binary_crossentropy: 0.6739\n",
            "Epoch 14/20\n",
            "32561/32561 - 3s - loss: 0.2542 - acc: 0.8817 - binary_crossentropy: 0.2542 - val_loss: 0.7768 - val_acc: 0.7860 - val_binary_crossentropy: 0.7768\n",
            "Epoch 15/20\n",
            "32561/32561 - 3s - loss: 0.2513 - acc: 0.8823 - binary_crossentropy: 0.2513 - val_loss: 0.8396 - val_acc: 0.7777 - val_binary_crossentropy: 0.8396\n",
            "Epoch 16/20\n",
            "32561/32561 - 3s - loss: 0.2455 - acc: 0.8846 - binary_crossentropy: 0.2455 - val_loss: 0.8466 - val_acc: 0.7826 - val_binary_crossentropy: 0.8466\n",
            "Epoch 17/20\n",
            "32561/32561 - 3s - loss: 0.2397 - acc: 0.8890 - binary_crossentropy: 0.2397 - val_loss: 1.0145 - val_acc: 0.7476 - val_binary_crossentropy: 1.0145\n",
            "Epoch 18/20\n",
            "32561/32561 - 3s - loss: 0.2399 - acc: 0.8887 - binary_crossentropy: 0.2399 - val_loss: 0.9441 - val_acc: 0.7736 - val_binary_crossentropy: 0.9441\n",
            "Epoch 19/20\n",
            "32561/32561 - 3s - loss: 0.2338 - acc: 0.8909 - binary_crossentropy: 0.2338 - val_loss: 0.9151 - val_acc: 0.7909 - val_binary_crossentropy: 0.9151\n",
            "Epoch 20/20\n",
            "32561/32561 - 3s - loss: 0.2290 - acc: 0.8920 - binary_crossentropy: 0.2290 - val_loss: 0.8841 - val_acc: 0.7993 - val_binary_crossentropy: 0.8841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-cMp_lxEoOK",
        "colab_type": "code",
        "outputId": "0f6b1c4b-5da4-408b-c973-9653877fc67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "test_acc = baseline_model.evaluate(test_feature, test_label)\n",
        "print(baseline_model.metrics_names)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16281/16281 [==============================] - 1s 72us/sample - loss: 0.8841 - acc: 0.7993 - binary_crossentropy: 0.8841\n",
            "['loss', 'acc', 'binary_crossentropy']\n",
            "Test accuracy: [0.8841433085802768, 0.7992752, 0.88414353]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQJLQZ_eHra4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}