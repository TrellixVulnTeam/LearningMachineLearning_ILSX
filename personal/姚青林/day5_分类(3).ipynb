{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTyWvgEhbQwg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from numpy.linalg import inv\n",
    "from math import floor, log\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KUdkDNlObu7c"
   },
   "outputs": [],
   "source": [
    "def dataProcess_X(rawData):\n",
    "  # 先去除掉 sex，如果有 income 就去除掉， 没有就算了\n",
    "  # 因为 sex 是伯努利分布， 就只将 男女 变成 0，1 就好\n",
    "    if 'income' in rawData.columns:\n",
    "        Data = rawData.drop(['sex', 'income'], axis=1)\n",
    "    else:\n",
    "        Data = rawData.drop(['sex'], axis=1)\n",
    "    \n",
    "  # 将 object 的列先获取出来， ‘object’ 就是字符串的意思。 一般来说这是类别属性， 离散随机变量\n",
    "    listObjectColumn = [col for col in Data.columns if Data[col].dtypes == 'object']\n",
    "  # 将非 object 的列获取出来， 那就是数字类型的。 连续型的随机变量\n",
    "    listNonObjectColumn = [x for x in list(Data) if x not in listObjectColumn]\n",
    "  # 将数据进行切分， 把连续型的数据和非连续性的数据切分开来\n",
    "    ObjectData = Data[listObjectColumn]\n",
    "    NonObjectData = Data[listNonObjectColumn]\n",
    "  # 将之前的 sex 列 变成 01 插入\n",
    "    NonObjectData.insert(0, 'sex', (rawData['sex'] == 'Female').astype(np.int))\n",
    "  # 将离散随机变量独热编码\n",
    "   ObjectData = pd.get_dummies(ObjectData)\n",
    "  # 再将内容组合到一起\n",
    "    Data = pd.concat([NonObjectData, ObjectData], axis=1)\n",
    "    Data_x = Data.astype('int64')\n",
    "  # 中心化内容\n",
    "    Data_x = (Data_x - Data_x.mean()) / Data_x.std()\n",
    "    return Data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2IPZ9Nmb0En"
   },
   "outputs": [],
   "source": [
    "def dataProcess_Y(rawData):\n",
    "  df_y = rawData['income']\n",
    "  Data_y = pd.DataFrame((df_y == '>50K').astype('int64'), columns=['income'])\n",
    "  return Data_y\n",
    "\n",
    "def sigmoid(z):\n",
    "  res = 1 / (1.0 + np.exp(-z))\n",
    "  # clip 的 目的是不让极端情况出现\n",
    "  return np.clip(res, 1e-8, (1-(1e-8)))\n",
    "\n",
    "# 将顺序打乱\n",
    "def _shuffle(X, Y):\n",
    "  randomize = np.arange(X.shape[0])\n",
    "  np.random.shuffle(randomize)\n",
    "  return (X[randomize], Y[randomize])\n",
    "\n",
    "def split_valid_set(X, Y, percentage):\n",
    "  all_size = X.shape[0]\n",
    "  valid_size = int(floor(all_size * percentage))\n",
    "  \n",
    "  # 先打乱顺序， 再切分训练集和测试集\n",
    "  X, Y = _shuffle(X, Y)\n",
    "  X_valid, Y_valid = X[: valid_size], Y[: valid_size]\n",
    "  X_train, Y_train = X[valid_size: ], Y[valid_size: ]\n",
    "  \n",
    "  return X_train, Y_train, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1Deqt-Ib3Nw"
   },
   "outputs": [],
   "source": [
    "# 有了参数之后， 就能分析出sigmoid函数的预测结果啦\n",
    "# 打印之就OK了\n",
    "def valid(X, Y, w):\n",
    "  a = np.dot(w, X.T)\n",
    "  y = sigmoid(a)\n",
    "  y_ = np.around(y)\n",
    "  result = (np.squeeze(Y) == y_)\n",
    "  print('acc = %f' % (float(result.sum()) / result.shape[0]))\n",
    "  return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9v6l92sBenEp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 小批量梯度下降法\n",
    "def train(X_train, Y_train):\n",
    "  \n",
    "  lambda_2 = 0.3\n",
    "  w = np.zeros(len(X_train[0]))\n",
    "  l_rate = 0.03\n",
    "  batch_size = 32\n",
    "  train_dataz_size = len(X_train)\n",
    "  step_num = int(floor(train_dataz_size / batch_size))\n",
    "  epoch_num = 2000\n",
    "  list_cost = []\n",
    "\n",
    "  total_loss = 0.0\n",
    "  for epoch in range(1, epoch_num):\n",
    "      total_loss = 0.0\n",
    "      X_train, Y_train = _shuffle(X_train, Y_train)\n",
    "\n",
    "      for idx in range(1, step_num):\n",
    "          X = X_train[idx*batch_size:(idx+1)*batch_size]\n",
    "          Y = Y_train[idx*batch_size:(idx+1)*batch_size]\n",
    "\n",
    "          s_grad = np.zeros(len(X[0]))\n",
    "\n",
    "\n",
    "          z = np.dot(X, w)\n",
    "          y = sigmoid(z)\n",
    "          loss = y - np.squeeze(Y)\n",
    "\n",
    "          cross_entropy = -1 * (np.dot(np.squeeze(Y.T), np.log(y)) + np.dot((1 - np.squeeze(Y.T)), np.log(1 - y)))/ len(Y)\n",
    "          total_loss += cross_entropy\n",
    "\n",
    "          grad = np.sum(-1 * X * (np.squeeze(Y) - y).reshape((batch_size, 1)), axis=0)\n",
    "          grad = np.dot(X.T, loss)\n",
    "          # w = w - l_rate * grad - l_rate * lambda_2 * w\n",
    "          # Adagrad\n",
    "          s_grad += grad ** 2\n",
    "          ada = np.sqrt(np.sum(s_grad))\n",
    "          w = w - l_rate * grad / ada - (l_rate / ada) * lambda_2 * w\n",
    "\n",
    "      list_cost.append(total_loss)\n",
    "\n",
    "  # valid(X_valid, Y_valid, w)\n",
    "  plt.plot(np.arange(len(list_cost)), list_cost)\n",
    "  plt.title(\"Train Process\")\n",
    "  plt.xlabel(\"epoch_num\")\n",
    "  plt.ylabel(\"Cost Function (Cross Entropy)\")\n",
    "  plt.show()\n",
    "\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oDp62Y0xfzrZ"
   },
   "outputs": [],
   "source": [
    "trainData = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'], skipinitialspace=True)\n",
    "testData = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'], skipinitialspace=True, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "adbgse5dfRO9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# here is one more attribute in trainData\n",
    "x_train = dataProcess_X(trainData).drop(['native-country_Holand-Netherlands'], axis=1).values\n",
    "x_test = dataProcess_X(testData).values\n",
    "y_train = dataProcess_Y(trainData).values\n",
    "y_ans = dataProcess_Y(testData).values\n",
    "\n",
    "\n",
    "x_test = np.concatenate((np.ones((x_test.shape[0], 1)), x_test), axis=1)\n",
    "x_train = np.concatenate((np.ones((x_train.shape[0], 1)),x_train), axis=1)\n",
    "\n",
    "valid_set_percentage = 0.1\n",
    "X_train, Y_train, X_valid, Y_valid = split_valid_set(x_train, y_train, valid_set_percentage)\n",
    "\n",
    "w_train = train(X_train, Y_train)\n",
    "print('Training ...')\n",
    "valid(X_train, Y_train, w_train)\n",
    "\n",
    "print('Testing ...')\n",
    "y_ = valid(x_test, y_ans, w_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7u_KO282fSDC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "逻辑回归—薪资分类.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
